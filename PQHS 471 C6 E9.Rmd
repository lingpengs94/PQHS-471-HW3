---
title: "Week 6 charpter 7 Q9"
author: "Andrew Shan"
date: "April 9, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(MASS)
attach(Boston)
set.seed(471)
```


# Use the poly() function ?o ???t a cubic polynomial regression to predict nox using dis. Report the regression output, and plot the resulting data and polynomial ???ts.
```{r}
fit= lm(nox~poly(dis, 3), data = Boston)
summary(fit)
```

```{r}
dislims <- range(Boston$dis)
dis.grid<- seq(from = dislims[1], to= dislims[2], by = 0.1)
preds <- predict(fit, list(dis = dis.grid))
plot(nox ~ dis, data = Boston, col = "darkgrey?)
lines(dis.grid, preds, col = "red", lwd = 2)
```

The polynomial terms are significant. 

# (b) Plot the polynomial ???ts for a range of di???erent polynomial degrees (say, from 1 to 10), and report the associated residual sum of squares. 

```{r}
rss <- rep(NA, 10)
for (i in 1:10) {
    fit <- lm(nox ~ poly(dis, i), data = Boston)
    rss[i] <- sum(fit$residuals^2)
}
plot(1:10, rss, xlab = "Deg?ee", ylab = "RSS", type = "l")
```

Because the residual sum of squares decrease as the degree of polynomial increase, the minimum polynomial degrees is 10.

#  Perform cross-validation or another approach to select the optimal degree for the polynomial, a?d explain your results. 

```{r}
library(boot)
d <- rep(NA, 10)
for (i in 1:10) {
    fit <- glm(nox ~ poly(dis, i), data = Boston)
    d[i] <- cv.glm(Boston, fit, K = 10)$delta[2]
}
plot(1:10, d, xlab = "Degree", ylab = "Test MSE", type = "l")
```

Based ?n the result of 10-fold cross-validation, a polynomial of degree of 4 minmizes the Test MSE.

# (d) Use the bs() function to ???t a regression spline to predict nox using dis. Report the output for the ???t using four degrees of freedom. How did you choose the knots? Plot the resulting ???t.

```{r}
library(splines)
fit = lm(nox ~ bs(dis, knots = c(4, 7, 11)), data = Boston)
summary(fit)
```

```{r}
pred <- predict(fit, list(dis = dis.grid))
plot(nox ~ dis, data = Boston, col = "darkgrey")
lines(dis.grid, preds, col = "red", lwd = 2)
```

T?e summary shows that all terns in spline fit are significant. Plot shows that most points fit well except some extreme value. 

# (e) Now ???t a regression spline for a range of degrees of freedom, and plot the resulting ???ts and report the resulting RSS. Describe the results obtained. 

```{r}
rss <- rep(NA, 16)
for (i in 3:16) {
    fit <- lm(nox ~ bs(dis, df = i), data = Boston)
    rss[i] <- sum(fit$residuals^2)
}
plot(3:16, rss[-c(1, 2)], xlab = "Degrees of freedom", yl?b = "RSS", type = "l")
rss[-c(1,2)]
```

RSS decreases untill Df=14 and then slightly increase for 15 and 16.


#  Perform cross-validation or another approach in order to select the best degrees of freedom for a regression spline on this data. Describe yo?r results.

We use a 10-fold cross validation to find the best degree of freedom. 
```{r}
cv <- rep(NA, 16)
for (i in 3:16) {
    fit <- glm(nox ~ bs(dis, df = i), data = Boston)
    cv[i] <- cv.glm(Boston, fit, K = 10)$delta[1]
}
```
```{r}
plot(3:16, cv[?c(1, 2)], xlab = "Degrees of freedom", ylab = "Test MSE", type = "l")
```

Based on the result of 10-fold cross-validation, 5 degrees of freedom minmizes the Test MSE.